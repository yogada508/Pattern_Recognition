{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "x_test = np.load(\"x_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 300)\n"
     ]
    }
   ],
   "source": [
    "# 550 data with 300 features\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# It's a binary classification problem \n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "K-fold data partition: Implement the K-fold cross-validation function. Your function should take K as an argument and return a list of lists (len(list) should equal to K), which contains K elements. Each element is a list contains two parts, the first part contains the index of all training folds, e.g. Fold 2 to Fold 5 in split 1. The second part contains the index of validation fold, e.g. Fold 1 in  split 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(x_train, y_train, k=5):\n",
    "    indices = np.arange(len(x_train))\n",
    "    np.random.seed()\n",
    "    np.random.shuffle(indices)\n",
    "    folds = np.array_split(indices, k)\n",
    "    folds = np.array(folds)\n",
    "\n",
    "    k_fold = []\n",
    "    for i in range(k):\n",
    "        train_fold = np.delete(np.arange(k), i)\n",
    "        k_fold.append([np.concatenate((folds[train_fold]), axis=None), folds[i]])\n",
    "    return k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_data = cross_validation(x_train, y_train, k=10)\n",
    "assert len(kfold_data) == 10 # should contain 10 fold of data\n",
    "assert len(kfold_data[0]) == 2 # each element should contain train fold and validation fold\n",
    "assert kfold_data[0][1].shape[0] == 55 # The number of data in each validation fold should equal to training data divieded by K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 1, Training index: [ 1  2  4  5  6  7  8  9 10 11 12 13 15 16 18 19], Validation index: [ 0  3 14 17]\n",
      "Split: 2, Training index: [ 0  1  3  4  5  6  7  8  9 12 13 14 15 16 17 18], Validation index: [ 2 10 11 19]\n",
      "Split: 3, Training index: [ 0  2  3  4  5  6  7  8 10 11 14 15 16 17 18 19], Validation index: [ 1  9 12 13]\n",
      "Split: 4, Training index: [ 0  1  2  3  4  7  9 10 11 12 13 14 16 17 18 19], Validation index: [ 5  6  8 15]\n",
      "Split: 5, Training index: [ 0  1  2  3  5  6  8  9 10 11 12 13 14 15 17 19], Validation index: [ 4  7 16 18]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = np.arange(20)\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kfold_data= []\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    print(\"Split: %s, Training index: %s, Validation index: %s\" % (i+1, train_index, val_index))\n",
    "    kfold_data.append([train_index, val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(kfold_data) == 5 # should contain 5 fold of data\n",
    "assert len(kfold_data[0]) == 2 # each element should contains index of training fold and validation fold\n",
    "assert kfold_data[0][1].shape[0] == 4 # The number of data in each validation fold should equal to training data divieded by K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Using sklearn.svm.SVC to train a classifier on the provided train set and conduct the grid search of “C” and “gamma” to find the best parameters by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=1.0, kernel='rbf', gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code\n",
    "# C = 2, gamma = 0.001\n",
    "kfold_data = cross_validation(x_train, y_train, k=5)\n",
    "\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gamma = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "average_scores = np.zeros((len(C), len(gamma)))\n",
    "best_score = 0\n",
    "best_model = None\n",
    "best_hyperparameter = [0, 0]\n",
    "\n",
    "for i in range(len(C)):\n",
    "    for j in range(len(gamma)):\n",
    "        score = 0\n",
    "\n",
    "        for traing_idx, validation_idx in kfold_data:\n",
    "            clf = SVC(C=C[i], kernel='rbf', gamma=gamma[j])\n",
    "            clf.fit(x_train[traing_idx], y_train[traing_idx])\n",
    "            score += clf.score(x_train[validation_idx], y_train[validation_idx])\n",
    "\n",
    "        average_scores[i][j] = score / len(kfold_data)\n",
    "        if average_scores[i][j] > best_score:\n",
    "            best_score = average_scores[i][j]\n",
    "            best_model = clf\n",
    "            best_hyperparameter = [C[i], gamma[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 0.001] 0.8854545454545455\n"
     ]
    }
   ],
   "source": [
    "print(best_hyperparameter, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8958333333333334\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(x_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Plot the grid search results of your SVM. The x, y represents the hyperparameters of “gamma” and “C”, respectively. And the color represents the average score of validation folds\n",
    "You reults should be look like this reference image below ![image](https://miro.medium.com/max/1296/1*wGWTup9r4cVytB5MOnsjdQ.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Train your SVM model by the best parameters you found from question 2 on the whole training set and evaluate the performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(x_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
